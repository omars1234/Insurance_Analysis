{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>*Regression Modelling for Severity as a Target Feature*</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"]=(20,10)\n",
    "import seaborn as sns;sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error,r2_score,mean_absolute_error,root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV,cross_val_score,KFold\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from tqdm import tqdm\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK,Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/Data_Sets/data_car.csv\")\n",
    "df=df.drop([\"X_OBSTAT_\",\"clm\",\"numclaims\"],axis=1)\n",
    "df[\"agecat\"]=df[\"agecat\"].astype(\"object\")\n",
    "df[\"veh_age\"]=df[\"veh_age\"].astype(\"object\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['veh_age', 'agecat','area','gender']).reset_index().drop(\"index\",axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Date preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_encoder=LabelEncoder()\n",
    "for col in df:\n",
    "    if col in list(df.select_dtypes(include=\"object\").columns):\n",
    "        df[col]=categories_encoder.fit_transform(df[col])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df[\"claimcst0\"]>0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define x and y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shaffled=df.sample(frac=1)\n",
    "x=df_shaffled.drop([\"claimcst0\"],axis=1)\n",
    "y=df_shaffled[\"claimcst0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split=round(.7*len(df_shaffled))\n",
    "valid_split=round(train_split+.15*len(df_shaffled))\n",
    "x_train,y_train=x[:train_split],y[:train_split]\n",
    "x_valid,y_valid=x[train_split:valid_split],y[train_split:valid_split]\n",
    "x_test,y_test=x[valid_split:],y[valid_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train),len(x_valid),len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_preds(y_test,predicted):\n",
    "    MSE=mean_squared_error(y_test,predicted)\n",
    "    RMSE=root_mean_squared_error(y_test,predicted)\n",
    "    MAE=mean_absolute_error(y_test,predicted)\n",
    "    r2=r2_score(y_test,predicted)\n",
    "    metrics_dict={\n",
    "        \"MSE\": f\"{MSE:.2f}\",\n",
    "        \"RMSE\":f\"{RMSE:.2f}\",\n",
    "        \"MAE\":f\"{MAE:.2f}\",\n",
    "        \"r2\":f\"{r2:.2f}\",\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestRegressor()\n",
    "clf.fit(x_train,y_train)\n",
    "y_preds=clf.predict(x_test)\n",
    "evaluation_preds(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"base\":evaluation_preds(y_test,y_preds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Splitting data into training and testing subsets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y ,test_size= 0.20)\n",
    "\n",
    "print(\"Train data shape of X = % s and Y = % s : \"%(\n",
    "\tx_train.shape, y_train.shape))\n",
    "\n",
    "print(\"Test data shape of X = % s and Y = % s : \"%(\n",
    "\tx_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Scalling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluation_preds(model,x,y):\n",
    "    NRMSE=cross_val_score(model, x,y,scoring=\"neg_mean_squared_error\").mean()\n",
    "    NRASE=cross_val_score(model, x,y,scoring=\"neg_mean_absolute_error\").mean()\n",
    "    r2=cross_val_score(model, x,y,scoring=\"r2\").mean()\n",
    "    metrics_dict={\n",
    "        \"NRMSE\": NRMSE,\n",
    "        \"NRASE\": NRASE,\n",
    "        \"r2\":r2\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_preds(model,y_test,predicted):\n",
    "    MSE=mean_squared_error(y_test,predicted)\n",
    "    RMSE=root_mean_squared_error(y_test,predicted)\n",
    "    MAE=mean_absolute_error(y_test,predicted)\n",
    "    r2=r2_score(y_test,predicted)\n",
    "    metrics_dict={\n",
    "        \"MSE\": MSE,\n",
    "        \"RMSE\":RMSE,\n",
    "        \"MAE\":MAE,\n",
    "        \"r2\":r2,\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Hyperparamers tunning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Defining models and its parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "                \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "                \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "                \"XGBRFRegressor\": XGBRFRegressor(),\n",
    "                \"GradientBoostingRegressor\":GradientBoostingRegressor(),\n",
    "                \"AdaBoostRegressor\": AdaBoostRegressor()\n",
    "        \n",
    "}\n",
    "\n",
    "search_spaces ={        \n",
    "        \"XGBRFRegressor\":{\n",
    "            \"learning_rate\": hp.uniform(\"learning_rate\",0.01,1.0),    # 0.3 is the default\n",
    "            \"max_depth\": hp.choice(\"max_depth\", [None,2, 4, 5, 6,7,8]),\n",
    "            \"subsample\": hp.uniform(\"subsample\",0.5,1.0),\n",
    "            \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]),\n",
    "            'colsample_bytree': hp.uniform(\"colsample_bytree\",0.5,1.0), \n",
    "            'colsample_bynode': hp.uniform(\"colsample_bynode\",0.5,1.0),\n",
    "            \"reg_lambda\": hp.quniform(\"reg_lambda\",0,2,1),           #L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "            \"reg_alpha\": hp.quniform(\"reg_alpha\",0,2,1),\n",
    "            \"num_parallel_tree\": hp.choice(\"num_parallel_tree\", [100,110])\n",
    "            },\n",
    "                    \n",
    "        \"GradientBoostingRegressor\":{\n",
    "            #\"loss\": hp.choice(\"loss\",['squared_error', 'huber', 'absolute_error', 'quantile']),\n",
    "            \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]),\n",
    "            \"max_depth\": hp.choice(\"max_depth\", [2, 4, 5, 6,7,8]),\n",
    "            \"max_features\": hp.choice(\"max_features\",[\"sqrt\", \"log2\"]),\n",
    "            \"learning_rate\": hp.uniform(\"learning_rate\",0.01,1.0),\n",
    "            \"subsample\": hp.uniform(\"subsample\",0.8,1.0),\n",
    "            \"min_samples_split\": hp.uniform(\"min_samples_split\",0.8,1.0),\n",
    "            \"min_samples_leaf\": hp.uniform(\"min_samples_leaf\",0.8,1.0),\n",
    "            #\"criterion\": hp.choice(\"criterion\",[\"squared_error\", \"friedman_mse\"]) \n",
    "            },\n",
    "        \"RandomForestRegressor\":{\n",
    "            \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]), \n",
    "            \"min_samples_split\": hp.uniform(\"min_samples_split\",0.8,1.0),\n",
    "            \"min_samples_leaf\": hp.uniform(\"min_samples_leaf\",0.8,1.0),\n",
    "            #\"bootstrap\": hp.choice(\"bootstrap\",[True, False]),                                                                                                    \n",
    "            #\"max_features\": hp.choice(\"max_features\",[\"sqrt\", \"log2\"]),                                    \n",
    "            \"max_depth\": hp.choice(\"max_depth\", [2, 4, 5, 6,7,8]),\n",
    "            #\"criterion\": hp.choice(\"criterion\",[\"poisson\", \"squared_error\", \"friedman_mse\",\"absolute_error\"])                    \n",
    "        },\n",
    "\n",
    "        \"AdaBoostRegressor\":{\n",
    "            \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]),\n",
    "            \"learning_rate\": hp.uniform(\"learning_rate\",0.01,1.0),\n",
    "            #\"loss\": hp.choice(\"loss\",[\"linear\",\"square\",\"exponential\"])\n",
    "        },\n",
    "        \"DecisionTreeRegressor\": {\n",
    "                    \"criterion\": hp.choice(\"criterion\",[\"poisson\", \"squared_error\", \"friedman_mse\",\"absolute_error\"]),\n",
    "                    'splitter': hp.choice(\"splitter\",[\"best\", \"random\"]),\n",
    "                    \"max_depth\": hp.choice(\"max_depth\", [2, 4, 5, 6,7,8]),\n",
    "                    \"min_samples_split\": hp.uniform(\"min_samples_split\",0.8,1.0),\n",
    "                    \"min_samples_leaf\": hp.uniform(\"min_samples_leaf\",0.8,1.0),\n",
    "                    \"max_features\": hp.choice(\"max_features\",[\"sqrt\", \"log2\"])\n",
    "        }                    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "print(\"RF_cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(RandomForestRegressor(),x,y))\n",
    "print(\"===========\")\n",
    "print(\"XGBRF_cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(XGBRFRegressor(),x,y))\n",
    "print(\"===========\")\n",
    "print(\"ADABOOST_cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(AdaBoostRegressor(),x,y))\n",
    "print(\"===========\")\n",
    "print(\"GRADBOOST_cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(GradientBoostingRegressor(),x,y))\n",
    "print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodels=pd.DataFrame({\n",
    "    \"RF_cross_val_evaluation_preds\":cross_val_evaluation_preds(RandomForestRegressor(),x,y),\n",
    "    \"XGBRF_cross_val_evaluation_preds\":cross_val_evaluation_preds(XGBRFRegressor(),x,y),\n",
    "    \"ADABOOST_cross_val_evaluation_preds\" :cross_val_evaluation_preds(AdaBoostRegressor(),x,y),\n",
    "    \"GRADBOOST_cross_val_evaluation_preds\":cross_val_evaluation_preds(GradientBoostingRegressor(),x,y)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *AdaBoostRegressor hyperparameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space=search_spaces[\"AdaBoostRegressor\"]\n",
    "def hyperparameter_tuning(space):\n",
    "    clf = AdaBoostRegressor(**space)\n",
    "    acc = cross_val_score(clf, x,y,scoring=\"neg_mean_absolute_error\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best_AdaBoostRegressor = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=10, \n",
    "    trials=trials\n",
    ")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *GradientBoostingRegressor hyperparameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space=search_spaces[\"GradientBoostingRegressor\"]\n",
    "def hyperparameter_tuning(space):\n",
    "    clf = GradientBoostingRegressor(**space)\n",
    "    acc = cross_val_score(clf, x_train,y_train,scoring=\"neg_mean_absolute_error\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best_GradientBoostingRegressor = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=10, \n",
    "    trials=trials\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *RandomForestRegressor hyperparameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space=search_spaces[\"RandomForestRegressor\"]\n",
    "def hyperparameter_tuning(space):\n",
    "    clf = RandomForestRegressor(**space)\n",
    "    acc = cross_val_score(clf, x,y,scoring=\"neg_mean_absolute_error\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best_RandomForestRegressor = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=10, \n",
    "    trials=trials\n",
    ")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *XGBRFRegressor hyperparameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space=search_spaces[\"XGBRFRegressor\"]\n",
    "def hyperparameter_tuning(space):\n",
    "    clf = XGBRFRegressor(**space)\n",
    "    acc = cross_val_score(clf, x,y,scoring=\"neg_mean_absolute_error\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best_XGBRFRegressor = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=10, \n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===========best_parametrs: AdaBoostRegressor===========\")\n",
    "print(best_AdaBoostRegressor)\n",
    "import pickle\n",
    "with open('C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_AdaBoostRegressor.pkl', 'wb') as f:\n",
    "    pickle.dump(best_AdaBoostRegressor, f)\n",
    "    f.close()\n",
    "print(\"===========best_parametrs: GradientBoostingRegressor===========\")\n",
    "print(best_GradientBoostingRegressor)\n",
    "import pickle\n",
    "with open('C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_GradientBoostingRegressor.pkl', 'wb') as f:\n",
    "    pickle.dump(best_GradientBoostingRegressor, f)\n",
    "    f.close()\n",
    "print(\"===========best_parametrs: RandomForestRegressor===========\")\n",
    "print(best_RandomForestRegressor)\n",
    "with open('C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_RandomForestRegressor.pkl', 'wb') as f:\n",
    "    pickle.dump(best_RandomForestRegressor, f)\n",
    "    f.close() \n",
    "print(\"===========best_parametrs: XGBRFRegressor===========\")\n",
    "print(best_XGBRFRegressor)\n",
    "with open('C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_XGBRFRegressor.pkl', 'wb') as f:\n",
    "    pickle.dump(best_XGBRFRegressor, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pickle\n",
    "pickle.load(open(\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_AdaBoostRegressor.pkl\",\"rb\"))\n",
    "pickle.load(open(\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_GradientBoostingRegressor.pkl\",\"rb\"))\n",
    "pickle.load(open(\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_RandomForestRegressor.pkl\",\"rb\"))\n",
    "pickle.load(open(\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/gender_best_XGBRFRegressor.pkl\",\"rb\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===========AdaBoostRegressor===========\")\n",
    "model = AdaBoostRegressor(**best_AdaBoostRegressor)\n",
    "model.fit(x_train,y_train)\n",
    "predicted=model.predict(x_test)\n",
    "print(\"cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(model,x,y))\n",
    "print(\"===========\")\n",
    "print(\"evaluation_preds :\\n\" , evaluation_preds(model,y_test,predicted))\n",
    "ADAboost_evaluation_preds=evaluation_preds(model,y_test,predicted)  \n",
    "print(\"===========\")\n",
    "\n",
    "print(\"===========GradientBoostingRegressor===========\")\n",
    "model = GradientBoostingRegressor(**best_GradientBoostingRegressor)\n",
    "model.fit(x_train,y_train)\n",
    "predicted=model.predict(x_test)\n",
    "print(\"cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(model,x,y))\n",
    "print(\"===========\")\n",
    "print(\"evaluation_preds :\\n\" , evaluation_preds(model,y_test,predicted)) \n",
    "GBOOST_evaluation_preds=evaluation_preds(model,y_test,predicted)  \n",
    "print(\"===========\")\n",
    "\n",
    "print(\"===========XGBRFRegressor===========\")\n",
    "model = XGBRFRegressor(**best_XGBRFRegressor)\n",
    "model.fit(x_train,y_train)\n",
    "predicted=model.predict(x_test)\n",
    "print(\"cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(model,x,y))\n",
    "print(\"===========\")\n",
    "print(\"evaluation_preds :\\n\" , evaluation_preds(model,y_test,predicted))\n",
    "XGBRF_evaluation_preds=evaluation_preds(model,y_test,predicted)   \n",
    "print(\"===========\")\n",
    "\n",
    "print(\"===========RandomForestRegressor===========\")\n",
    "model = RandomForestRegressor(**best_RandomForestRegressor)\n",
    "model.fit(x_train,y_train)\n",
    "predicted=model.predict(x_test)\n",
    "print(\"cross_val_evaluation_preds :\\n\" , cross_val_evaluation_preds(model,x,y))\n",
    "print(\"===========\")\n",
    "print(\"evaluation_preds :\\n\" , evaluation_preds(model,y_test,predicted))\n",
    "RF_evaluation_preds=evaluation_preds(model,y_test,predicted)\n",
    "print(\"=====================================================================\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**best_RandomForestRegressor)\n",
    "model.fit(x_train,y_train)\n",
    "predicted=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperoptmodels=pd.DataFrame({\n",
    "    \"RF_cross_val_evaluation_preds\":RF_evaluation_preds,\n",
    "    \"XGBRF_cross_val_evaluation_preds\":XGBRF_evaluation_preds,\n",
    "    \"ADABOOST_cross_val_evaluation_preds\" :ADAboost_evaluation_preds,\n",
    "    \"GRADBOOST_cross_val_evaluation_preds\":GBOOST_evaluation_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperoptmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperoptmodels.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open (\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestParams/claims_best_XGBRFRegressor.pkl\",\"wb\") as f:\n",
    "    pickle.dump(best_XGBRFRegressor,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Final Result*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRFRegressor(**best_XGBRFRegressor)\n",
    "model.fit(x_train,y_train)\n",
    "predicted=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_names=x.columns\n",
    "importance=pd.concat([pd.DataFrame(model.feature_names,columns=[\"feature_names\"]),\n",
    "           pd.DataFrame(model.feature_importances_,columns=[\"feature_importances\"])],axis=1)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"]=(20,7)\n",
    "ax=sns.barplot(x=np.round(importance[\"feature_importances\"],3),y=importance[\"feature_names\"])\n",
    "plt.title('Features importance for claims feature')\n",
    "ax.bar_label(ax.containers[0]);\n",
    "plt.savefig('C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/featuresImportanceGraphs/claims_featureImportanc.png',dpi=500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open (\"C:/Users/Omar/Desktop/Omar_Files/Python_Analysis/Auto_Insurance/outcomes/bestModels/claims_prediction_model.pkl\",\"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
